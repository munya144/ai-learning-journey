{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T06:59:50.964012600Z",
     "start_time": "2026-02-02T06:59:46.930082500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ЗАДАЧА 1: Image Classification\n",
    "import time\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Устройство\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Трансформации (одинаковые для всех моделей ImageNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Модели\n",
    "models_dict = {\n",
    "    \"resnet50\": models.resnet50(weights=\"IMAGENET1K_V2\"),\n",
    "    \"mobilenet_v2\": models.mobilenet_v2(weights=\"IMAGENET1K_V2\"),\n",
    "    \"efficientnet_b0\": models.efficientnet_b0(weights=\"IMAGENET1K_V1\"),\n",
    "}\n",
    "\n",
    "# Переводим в eval и на устройство\n",
    "for name, model in models_dict.items():\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    models_dict[name] = model\n",
    "\n",
    "# Несколько картинок (публичные ссылки, рабочие на 2026)\n",
    "image_urls = [\n",
    "    \"https://images.unsplash.com/photo-1583511655857-d19b40a7a54e?w=800&auto=format&fit=crop&q=80\",\n",
    "    \"https://images.unsplash.com/photo-1615751072497-5f5169febe17?w=800&auto=format&fit=crop&q=80\",\n",
    "    \"https://images.unsplash.com/photo-1560807707-8cc77767d783?w=800&auto=format&fit=crop&q=80\",\n",
    "    \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800&auto=format&fit=crop&q=80\",\n",
    "    \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=800&auto=format&fit=crop&q=80\",\n",
    "]\n",
    "\n",
    "\n",
    "# Классы ImageNet (можно загрузить, но для примера берём топ-1)\n",
    "def get_top_pred(output, topk=1):\n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "    values, indices = probs.topk(topk)\n",
    "    return indices[0].item(), values[0].item()\n",
    "\n",
    "\n",
    "print(\"Модель\\t\\tКласс\\tВероятность\\tВремя (мс)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for url in image_urls[:5]:\n",
    "    print(f\"\\nИзображение: {url.split('/')[-1][:10]}...\")\n",
    "\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    for name, model in models_dict.items():\n",
    "        t0 = time.time()\n",
    "        with torch.no_grad():\n",
    "            out = model(input_tensor)\n",
    "        dt = (time.time() - t0) * 1000\n",
    "\n",
    "        cls, prob = get_top_pred(out)\n",
    "        print(f\"{name:<15}\\t{cls:>4}\\t{prob:.4f}\\t{dt:.1f} ms\")\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# 1. Загрузить 2-3 разные pretrained модели (ResNet, MobileNet, EfficientNet)\n",
    "# 2. Сделать inference на 5-10 картинках\n",
    "# 3. Сравнить результаты и скорость\n",
    "# 4. Понять: как выбирать модель для задачи"
   ],
   "id": "c5b60f84d05d68ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель\t\tКласс\tВероятность\tВремя (мс)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Изображение: photo-1583...\n",
      "resnet50       \t 245\t0.4607\t59.5 ms\n",
      "mobilenet_v2   \t 245\t0.6492\t16.3 ms\n",
      "efficientnet_b0\t 245\t0.9903\t22.4 ms\n",
      "\n",
      "Изображение: photo-1615...\n",
      "resnet50       \t 157\t0.1413\t64.3 ms\n",
      "mobilenet_v2   \t 263\t0.1586\t19.4 ms\n",
      "efficientnet_b0\t 263\t0.1698\t27.5 ms\n",
      "\n",
      "Изображение: photo-1560...\n",
      "resnet50       \t 156\t0.4624\t54.0 ms\n",
      "mobilenet_v2   \t 156\t0.5564\t14.9 ms\n",
      "efficientnet_b0\t 156\t0.8555\t19.4 ms\n",
      "\n",
      "Изображение: photo-1506...\n",
      "resnet50       \t 970\t0.1946\t55.0 ms\n",
      "mobilenet_v2   \t 970\t0.1569\t15.0 ms\n",
      "efficientnet_b0\t 970\t0.5285\t18.7 ms\n",
      "\n",
      "Изображение: photo-1514...\n",
      "resnet50       \t 285\t0.1644\t55.2 ms\n",
      "mobilenet_v2   \t 281\t0.0631\t12.5 ms\n",
      "efficientnet_b0\t 285\t0.1959\t19.6 ms\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T07:20:42.277876900Z",
     "start_time": "2026-02-02T07:20:42.141571300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Параметры\n",
    "VOCAB_SIZE = 50000\n",
    "EMB_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 2  # например positive / negative\n",
    "\n",
    "\n",
    "# 1. Простая модель LSTM-классификатор\n",
    "class TextLSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMB_DIM, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(EMB_DIM, HIDDEN_DIM, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM * 2, NUM_CLASSES)  # ×2 из-за bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)  # [batch, seq_len] → [batch, seq_len, emb]\n",
    "        _, (hn, _) = self.lstm(embeds)  # берём последний hidden state\n",
    "        hn = torch.cat((hn[-2, :, :], hn[-1, :, :]), dim=1)  # bidirectional\n",
    "        out = self.fc(hn)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Пример создания\n",
    "model = TextLSTMClassifier()\n",
    "print(model)\n",
    "\n",
    "# 2. Загрузка GloVe (пример — torchtext уже не рекомендуется, лучше вручную)\n",
    "# Скачать glove.6B.300d.txt → https://nlp.stanford.edu/projects/glove/\n",
    "# Затем загрузить веса в embedding слой (очень упрощённо):\n",
    "\n",
    "# embedding_matrix = torch.zeros(VOCAB_SIZE, EMB_DIM)\n",
    "# ... (заполняем по словарю)\n",
    "# model.embedding.weight.data.copy_(embedding_matrix)\n",
    "# model.embedding.weight.requires_grad = False   # можно заморозить"
   ],
   "id": "ae5069d8195c834d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextLSTMClassifier(\n",
      "  (embedding): Embedding(50000, 300, padding_idx=0)\n",
      "  (lstm): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T07:20:51.555643800Z",
     "start_time": "2026-02-02T07:20:51.276449300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Берём предобученную модель\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# Замораживаем все параметры\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Меняем последний слой под свою задачу (например 10 классов)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 10)  # ← только этот слой будет обучаться\n",
    "\n",
    "# Альтернатива: размораживаем последние блоки\n",
    "# for param in model.layer4.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# Теперь обучаем только fc (или fc + layer4)\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "print(\"Обучаемых параметров:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ],
   "id": "35e3abe19a4b0034",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаемых параметров: 5130\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3c3ff1d5974a73d0"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
