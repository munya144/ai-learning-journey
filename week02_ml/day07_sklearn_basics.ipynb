{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T06:23:16.837184100Z",
     "start_time": "2026-01-31T06:23:16.694137900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==================== 1. ЗАГРУЗКА ДАННЫХ ====================\n",
    "url = 'C:/Users/6muni/Documents/adult.csv'  # ссылка на датасет (Adult Income)\n",
    "adult = pd.read_csv(url)\n",
    "# print(adult.info())\n",
    "\n",
    "# ==================== 2. ПРЕОБРАЗОВАНИЕ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ ====================\n",
    "# Преобразуем в бинарный формат\n",
    "adult['income'] = adult['income'].str.strip().map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "print(f\"\\nУникальные значения после преобразования: {adult['income'].unique()}\")\n",
    "print(f\"Пропущенные значения: {adult['income'].isna().sum()}\")\n",
    "\n",
    "# Проверяем баланс классов\n",
    "class_distribution = adult['income'].value_counts(normalize=True) * 100\n",
    "print(f\"\\nРаспределение классов в исходных данных:\")\n",
    "print(f\"  Класс 0 (<=50K): {class_distribution[0]:.2f}% ({adult['income'].value_counts()[0]} samples)\")\n",
    "print(f\"  Класс 1 (>50K):  {class_distribution[1]:.2f}% ({adult['income'].value_counts()[1]} samples)\")\n",
    "\n",
    "# ==================== 3. РАЗДЕЛЕНИЕ НА ПРИЗНАКИ И ЦЕЛЕВУЮ ====================\n",
    "# Разделяем на признаки (X) и целевую переменную (y)\n",
    "X = adult.drop('income', axis=1)\n",
    "y = adult['income']\n",
    "\n",
    "# ==================== 4. РАЗДЕЛЕНИЕ НА TRAIN/TEST ====================\n",
    "# Разделение на train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,  # 20% на тест\n",
    "    random_state=42,  # для воспроизводимости\n",
    "    stratify=y  # стратификация по income\n",
    ")\n",
    "\n",
    "# ==================== 5. ПРОВЕРКА РАЗМЕРОВ ====================\n",
    "print(\n",
    "    f\"\\nРазмеры выборок для X_train: {X_train.shape} ({(X_train.shape[0] / len(adult) * 100):.1f}% от исходных), y_train: {y_train.shape}\")\n",
    "print(\n",
    "    f\"Размеры выборок для X_train: {X_test.shape} ({(X_test.shape[0] / len(adult) * 100):.1f}% от исходных), y_train: {y_test.shape}\")\n",
    "\n",
    "# ==================== 6. ПРОВЕРКА STRATIFY ====================\n",
    "print(\"\\nПроверка stratify:\")\n",
    "print(f\"Оригинал: {y.value_counts(normalize=True).values}\")\n",
    "print(f\"Train:    {y_train.value_counts(normalize=True).values}\")\n",
    "print(f\"Test:     {y_test.value_counts(normalize=True).values}\")\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# 1) Правильно разделить на train/test (80/20)\n",
    "# 2) Проверить stratify (для classification)\n",
    "# 3) Установить random_state для воспроизводимости\n",
    "# 4) Проверить размеры и распределение классов"
   ],
   "id": "38ce6177d2ff221f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Уникальные значения после преобразования: [0 1]\n",
      "Пропущенные значения: 0\n",
      "\n",
      "Распределение классов в исходных данных:\n",
      "  Класс 0 (<=50K): 76.07% (37155 samples)\n",
      "  Класс 1 (>50K):  23.93% (11687 samples)\n",
      "\n",
      "Размеры выборок для X_train: (39073, 14) (80.0% от исходных), y_train: (39073,)\n",
      "Размеры выборок для X_train: (9769, 14) (20.0% от исходных), y_train: (9769,)\n",
      "\n",
      "Проверка stratify:\n",
      "Оригинал: [0.76071823 0.23928177]\n",
      "Train:    [0.76072992 0.23927008]\n",
      "Test:     [0.76067151 0.23932849]\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T08:02:55.857635800Z",
     "start_time": "2026-01-31T08:02:55.784826800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Копируем данные для преобразований\n",
    "X_processed = X.copy()\n",
    "\n",
    "# Предварительная обработка столбцов\n",
    "cat_cols_original = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nКатегориальные признаки ДО: \\n\\t{cat_cols_original}\")\n",
    "num_cols_original = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nЧисловые признаки ДО: \\n\\t{num_cols_original}\")\n",
    "\n",
    "# ==================== 1. POLYNOMIAL FEATURES ====================\n",
    "X_processed['age_squared'] = X_processed['age'] ** 2\n",
    "X_processed['hours_squared'] = X_processed['hours-per-week'] ** 2\n",
    "\n",
    "# ==================== 2. INTERACTION FEATURES ====================\n",
    "X_processed['age_hours'] = X_processed['age'] * X_processed['hours-per-week']\n",
    "\n",
    "# ==================== 3. BINNING ====================\n",
    "age_bins = [0, 25, 45, 65, 100]\n",
    "age_labels = ['young', 'middle', 'senior', 'elder']\n",
    "X_processed['age_bin'] = pd.cut(X_processed['age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "\n",
    "# ==================== 4. ONE-HOT ENCODING ====================\n",
    "# Применяем one-hot к ВСЕМ категориальным признакам (включая созданный age_bin)\n",
    "X_processed = pd.get_dummies(X_processed, drop_first=True)\n",
    "\n",
    "# ==================== 5. LABEL ENCODING (пример, если нужно) ====================\n",
    "# Уместно, если есть естественный порядок внутри категории. Пример:\n",
    "# education = [\"Preschool\", \"HighSchool\", \"Bachelors\"] → можно закодировать как 0,1,2.\n",
    "# Неуместно, когда порядок искусственный.\n",
    "\n",
    "# Создадим отдельный DataFrame с label encoding ТОЛЬКО для education\n",
    "# (перед one-hot кодированием нужно было бы сохранить оригинальный education)\n",
    "# Примечание: Label Encoding делаем ДО one-hot, если нужен\n",
    "\n",
    "# Пример для education:\n",
    "# education_map = {'Preschool':0, 'HS-grad':1, 'Bachelors':2, ...}\n",
    "# X_processed['education_label'] = X['education'].map(education_map)\n",
    "\n",
    "\n",
    "# Итог\n",
    "num_cols_processed = X_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nИтого: {X_processed.shape[1]} признаков после преобразований\")\n",
    "print(\n",
    "    f\"\\nКатегориальные признаки ПОСЛЕ: \\n\\t{len(cat_cols_original)} категориальных признаков преобразованы в {X_processed.shape[1] - len(num_cols_original) - 3} бинарных признака\")\n",
    "print(f\"\\nЧисловые признаки ПОСЛЕ: \\n\\t{num_cols_processed}\")\n",
    "\n",
    "\n",
    "# TODO: Создать новые признаки\n",
    "# 1) Polynomial features\n",
    "# 2) Interaction features (A * B, A / B)\n",
    "# 3) Binning (категоризация непрерывных признаков)\n",
    "# 4) One-hot encoding для категориальных\n",
    "# 5) Label encoding (когда это ok, когда нет)"
   ],
   "id": "4ed8b198b7849ce5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Категориальные признаки ДО: \n",
      "\t['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
      "\n",
      "Числовые признаки ДО: \n",
      "\t['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\n",
      "Итого: 106 признаков после преобразований\n",
      "\n",
      "Категориальные признаки ПОСЛЕ: \n",
      "\t8 категориальных признаков преобразованы в 97 бинарных признака\n",
      "\n",
      "Числовые признаки ПОСЛЕ: \n",
      "\t['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'age_squared', 'hours_squared', 'age_hours']\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T09:04:54.138173900Z",
     "start_time": "2026-02-01T09:04:53.579942300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Определяем числовые и категориальные признаки (из оригинальных данных)\n",
    "num_cols_original = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols_original = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Преобразования\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols_original),\n",
    "        ('cat', cat_transformer, cat_cols_original)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Полный pipeline с моделью\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Обучаем одной командой\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Итог\n",
    "print(\"Pipeline успешно создан и обучен на train-данных.\")\n",
    "print(f\"Score на train: {pipeline.score(X_train, y_train):.4f}\")\n",
    "print(f\"Score на test:  {pipeline.score(X_test, y_test):.4f}\")\n",
    "\n",
    "# TODO: Создать pipeline\n",
    "# 1) Для числовых: StandardScaler\n",
    "# 2) Для категориальных: OneHotEncoder\n",
    "# 3) Объединить в ColumnTransformer\n",
    "# 4) Добавить модель в конец pipeline\n",
    "# 5) Обучить одной командой: pipeline.fit(X_train, y_train)"
   ],
   "id": "97c1a76400f7c779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline успешно создан и обучен на train-данных.\n",
      "Score на train: 0.8537\n",
      "Score на test:  0.8538\n"
     ]
    }
   ],
   "execution_count": 93
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
